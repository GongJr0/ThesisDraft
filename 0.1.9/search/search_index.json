{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Introduction","text":"<p><code>SymbolicDSGE</code> is a linear DSGE engine with a completely symbolic model specification. Through <code>SymPy</code>, model components are parsed into expressions that can be adjusted, decomposed, and analyzed. This allows things like searching model parameters in a grid, quickly modifying and testing parsed equations, and more; All parsed components of the model support overriding and recompiling. Although the library is currently in very early development, current functionality includes:</p> <ul> <li>YAML-based model configuration</li> <li>Parser with a <code>SymPy</code> backend</li> <li><code>linearsolve</code> based solver</li> <li>IRF path/plot generation</li> <li>Simulation</li> <li>Shock generation interface with support for all <code>SciPy</code> distributions</li> <li>Data retrieval helper for FRED API</li> <li>Data transformation functions (HP filters, detrending, etc.)</li> <li>Kalman Filter implementation</li> </ul>","tags":["info"]},{"location":"contact/","title":"Contact","text":"<ul> <li> <p> Ask a Question     For general questions or clarifications.  Open Discussion</p> </li> <li> <p> Report a Bug     Something not working as expected.  File Bug Report</p> </li> <li> <p> Request a Feature     Suggest improvements or new capabilities.  Request Feature</p> </li> </ul>","tags":["info"]},{"location":"installation/","title":"Installation","text":"<p><code>SymbolicDSGE</code> can be installed via PyPI using the following command for use in a python environment.</p> <pre><code>pip install SymbolicDSGE\n</code></pre> <p>For people that want to modify or contribute to the project, forking the repository is advisable compared to a <code>pip install</code>. In the repository, you will find a <code>uv.lock</code> file. To interact with all components of the project using <code>uv sync --all-extras</code> is the quickest and easiest route. This will replicate the environment used at development and will include the <code>dev</code> dependency group for linting, auto formatting, etc.</p>","tags":["info"]},{"location":"Documentation/CompiledModel/","title":"CompiledModel","text":"<pre><code>@dataclass(frozen=True)\nclass CompiledModel()\n</code></pre> <p><code>CompiledModel</code> contains the model components mapped to numeric/vectorized/lambdified counterparts.</p> <p>Fields:</p> Name Type Description config <code>ModelConfig</code> Model config that was compiled. var_names <code>list[str]</code> Variables as strings. objective_eqs <code>list[sp.Expr]</code> Solver targets in symbolic representation. (not used in the solver) objective_funcs <code>list[Callable]</code> Solver objectives as standalone <code>Callable</code>s. equations <code>Callable</code> <code>objective_funcs</code> compiled into a single <code>Callable</code> target. (solver input) observable_names <code>list[str]</code> Observable variables as strings. observable_eqs <code>list[sp.Expr]</code> Measurement equations in symbolic representation. objective_funcs <code>list[Callable]</code> Measurement equations as <code>Callable</code>s. n_state <code>int</code> Number of state variables. n_exog <code>int</code> Number of exogenous variables. <p> </p> <p>Methods:</p> Signature Return Type Description <code>.to_dict()</code> <code>dict</code> <code>CompiledModel</code> in dictionary form.","tags":["doc"]},{"location":"Documentation/DSGESolver/","title":"DSGESolver","text":"<pre><code>class DSGESolver(model_config: ModelConfig, t: sp.Symbol = sp.Symbol('t', integer=True))\n</code></pre> <p>Class responsible for model compilation and solution.</p> <p>Attributes:</p> Name Type Description model_config <code>ModelConfig</code> Configuration object to be compiled/solved. t <code>sp.Symbol</code> Time symbol used in model components. <p>Methods:</p> <pre><code>DSGESolver.compile(\n    variable_order: list[sp.Function], \n    n_state: int = None, \n    n_exog: int = None, \n    params_order: list[str] = None\n    ) -&gt; CompiledModel \n</code></pre> Variable Ordering Convention <p>The model expects the first <code>n_exog</code> variables to be the exogenous components. Before solving the model either;</p> <ul> <li>Ensure the variable ordering in the config file follows this convention.</li> <li>Supply an order specification at compile time. </li> </ul> Planned Changes <p>Current input constraints will be eliminated as <code>SymbolicDSGE</code> moves towards the beta releases. <code>n_exog</code> and <code>n_state</code> will be inferred through flags in the config; and variable ordering will be managed internally. </p> <p>Produces a <code>CompiledModel</code> object respecting the given orders. <code>n_exog</code> and <code>n_state</code> must be supplied.</p> <p>Inputs:</p> Name Description variable_order Custom ordering of variables if desired. n_state Number of state variables. n_exog Number of exogenous variables. params_order Custom ordering of model parameters if desired. <p> </p> <p>Returns:</p> Type Description <code>CompiledModel</code> Numerically compiled model components returned as an object. <pre><code>SolvedModel.solve(\n    compiled: CompiledModel, \n    parameters: dict[str, float] = None, \n    steady_state: ndarray[float] | dict[str, float] = None, \n    log_linear: bool = False\n    ) -&gt; SolvedModel\n</code></pre> <p>Solves the given compiled model and returns a <code>SolvedModel</code> object.</p> <p>Inputs:</p> Name Description compiled The <code>CompiledModel</code> to solve. parameters parameter values as dict to override the calibration config. steady_state model variables' steady state. Defaults to zeroes. (often used in gap models) log_linear Indicates the model is in log-linear specification to the solver. <p> </p> <p>Returns:</p> Type Description <code>SolvedModel</code> Solved model object with relevant methods attached.","tags":["doc"]},{"location":"Documentation/ModelConfig/","title":"ModelConfig","text":"<pre><code>@dataclass\nclass ModelConfig()\n</code></pre> <p><code>ModelConfig</code> stores the parsed model as <code>SymPy</code> objects/expressions.</p> <p>Fields:</p> Name Type Description name <code>str</code> Model name. variables <code>list[sp.Function]</code> Variables as functions of time. constrained <code>dict[Function, bool]</code> Dictionary mapping functions to constraint status. parameters <code>list[sp.Symbol]</code> Model parameters as symbols. shocks <code>list[sp.Symbol]</code> Shock variables as symbols. observables <code>list[sp.Symbol]</code> Observable variables as symbols. equations <code>Equations</code> <code>dataclass</code> containing model, constraint, and observable equations. calibration <code>Calib</code> <code>dataclass</code> of parameter calibrations and shock-to-sigma mappings.","tags":["doc"]},{"location":"Documentation/ModelParser/","title":"ModelParser","text":"<pre><code>class ModelParser(config_path: str | pathlib.Path)\n</code></pre> <p><code>ModelParser</code> reads a given YAML configuration file (see configuration guide) and parses the contents into a <code>ModelConfig</code> object.</p> <p>Parameters:</p> Name Type Description config_path <code>str | pathlib.Path</code> Path to the YAML config file. config <code>ModelConfig</code> Parsed config object. <p> </p> <p>Methods:</p> Signature Return Type Description <code>.from_yaml()</code> <code>ModelConfig</code> Reads the file and populates <code>ModelParser.config</code>. Runs at <code>__init__</code>. <code>.get()</code> <code>ModelConfig</code> Returns the currently parsed model config. <code>.to_pickle(filepath: str | pathlib.Path)</code> <code>None</code> Serializes the current <code>ModelConfig</code> and saves to <code>filepath</code>.","tags":["doc"]},{"location":"Documentation/Shock/","title":"Shock","text":"<pre><code>class Shock(\n    T: int, \n    dist: Literal['norm', 't', 'uni'] | rv_generic | multi_rv_generic | None = None,\n    multivar: bool = False,\n    seed: int | None = 0, # (1)!\n    dist_args: tuple = (),\n    dist_kwargs: dict | None = None,\n    shock_arr: ndarray | None = None,\n    )\n</code></pre> <ol> <li>Notice the default behavior will produce seeded results. Pass <code>None</code> explicitly to disable this behavior.</li> </ol> <p><code>Shock</code> provides the infrastructure necessary to produce simulation shocks. All distributions that are subclasses of <code>SciPy</code>'s <code>rv_generic</code> and <code>multi_rv_generic</code> are supported by the interface. Moreover, Normal, Student-t, and Uniform shocks are supported natively inside the class object.</p> Multivariate Uniform Distribution Support <p>Multivariate uniforms are not identifiable even with known bounds and covariances. A specific support function must be supplied to determine an exact shape; with the exceptions of rectangular (no covariance) and ellipsoid (assumed shape) cases.</p> <p>Support functions, and derivation techniques for multivariate uniform distributions will not be implemented unless explicitly requested. </p> Custom Distributions <p>The underlying generators are written to accept any class implementing a <code>.rvs</code> method (abstract method from <code>SciPy</code>). Writing a subclass of either <code>SciPy</code> abstraction and implementing said method allows the of creation random values in any desired way.</p> Generator Factories <p>Generator factories being utilized in this class are currently not part of the public API of <code>SymbolicDSGE</code>. Robust and defensive alternatives of generators will be written specifically for the public API in future releases.</p> <p>Attributes:</p> Name Description T Period length to generate shocks for. dist Distribution to use when drawing random values. multivar Generate shocks for multiple correlated components if <code>True</code>. seed Random state seed. dist_args Positional arguments passed-through to the distribution's <code>.rvs</code> method. dist_kwargs Keyword arguments passed-through to the distribution's <code>.rvs</code> method. shock_arr Array of shock values to configure. <p> </p> <p>Methods:</p> <pre><code>Shock.shock_generator() -&gt; Callable[[float | ndarray[float]], ndarray]\n</code></pre> <p>Creates a callable that returns an entire shock array according to the class attributes when called.</p> <p>Inputs:</p> <p><code>None</code></p> <p>Returns:</p> Single Return <p>Only one <code>Callable</code> specification from the table below is returned.</p> Type(s) Description <code>Callable[[float], ndarray[float]]</code> Callable taking a single shock variance parameter. (This signature is returned for univariate shocks) <code>Callable[[ndarray[float]], ndarray[float]]</code> Callable taking a shock covariance matrix. (This signature is returned for multivariate shocks.) <p> </p> <pre><code>Shock.place_shocks(\n    shock_spec: dict[int, float],\n) -&gt; np.ndarray[float]\n</code></pre> <p>Modifies the specified indices of a given shock array to the corresponding values. (Returns a modified zero vector if <code>shock_arr</code> isn't specified in the class instance)</p> Multivariate Implementation <p><code>place_shocks</code> does not support multivariate adjustments as of now. This is a planned feature for version 0.2.0 of the alpha release cycle.</p> <p>Inputs:</p> Name Description shock_spec <code>dict</code> keys represent the time indices and values are the shocks that are placed in the corresponding index. <p>Returns:</p> Type Description <code>np.ndarray[float]</code> Array with specified indices modified as per the specification.","tags":["doc"]},{"location":"Documentation/SolvedModel/","title":"SolvedModel","text":"<pre><code>@dataclass(frozen=True)\nclass SolvedModel()\n</code></pre> <p><code>SolvedModel</code> contains the policy/transition matrices and relevant methods.</p> <p>Fields:</p> Name Type Description compiled <code>CompiledModel</code> The compiled model object that resulted in the current solution. policy <code>linearsolve.model</code> Solver backend output (e.g., stability diagnostics, eigenvalues, raw solver objects). A <code>np.ndarray</code> The discovered state-transition matrix. B <code>np.ndarray</code> The discovered innovation impact matrix. <p> </p> <p>Methods:</p> <pre><code>SolvedModel.sim(\n    T: int, \n    shocks: dict[str, Callable | np.ndarray], # (1)!\n    shock_scale: float = 1.0, # (2)!\n    x0: np.ndarray | None = None, \n    observables: bool = False\n) -&gt; dict[str, np.ndarray[float]]\n</code></pre> <ol> <li>The dictionary keys can be populated by:</li> <li>An array of shocks <code>(T, 1) | (T,)</code> when shocks are for a single variable and <code>(T, K)</code> when drawing correlated shocks simultaneously.</li> <li>A callable accepting either a shock variance descriptor (sigma) or a covariance matrix depending on univariate or multivariate requirements. The callable should return arrays shaped as described above. Per-step generators are not supported.</li> <li>Shocks are drawn from the specified distribution and all elements in the arrays are scaled by this parameter.</li> </ol> <p>Returns the simulated path defined by the given inputs.</p> Univariate Shock Syntax <p>A univariate shock is defined as a dictionary entry for the given variable. For example, if a model specifies a variable <code>x</code> and a shock symbol <code>e_x</code>, the dictionary would expect <code>{\"x\": ...}</code> where <code>...</code> is populated by a <code>ndarray</code> of shape <code>(T,)</code> or <code>(T,1)</code>, or by a univariate generator callable.</p> Correlated Shock Syntax <p>To define a set of variables with nonzero shock covariance, a shared dictionary entry should be used. For example, a multivariate shock to <code>x</code> and <code>y</code> should be defined as <code>{\"x,y\": ...}</code> where <code>...</code> is populated by a <code>(T, 2)</code> array or a multivariate generator callable.</p> <p>Details regarding the dictionary key scheme:</p> <ul> <li>Variable names are parsed by splitting on commas; surrounding whitespace is stripped.</li> <li>Multiple variables can be chained as required. There is no variable count limitation.</li> <li>The ordering of variables in the key does not affect simulation results.</li> <li>Shock realizations are always aligned with the innovation ordering defined at model configuration or compilation (<code>B</code> matrix order).</li> </ul> Multivariate Shock Canonicalization and Reproducibility <p>When multivariate shock generators are used, variables are internally reordered to a canonical model-defined order before sampling. This ensures that simulations are reproducible under a fixed random seed, regardless of the order in which variables are specified in the shock dictionary key (e.g. <code>\"g,z\"</code> vs <code>\"z,g\"</code>).</p> <p>This behavior is required because multivariate sampling methods (e.g. Cholesky-based Gaussian draws) are order-dependent at the realization level, even when the underlying covariance structure is permutation-invariant.</p> <p>Concretely:</p> <ul> <li>Correlation and covariance matrices are constructed after canonicalizing variable order.</li> <li>Sampling is performed in this canonical order.</li> <li>Shock realizations are then mapped to the correct innovation indices used by the model.</li> </ul> <p>As a result, variable ordering in multivariate shock keys does not affect either the statistical properties or the realized sample paths of the simulation when the random seed is fixed.</p> Custom Shock Generators <p>While it is technically possible to replicate the internal generator factory\u2019s behavior, this is strongly discouraged. Custom shock distributions and array manipulations are supported via the <code>Shock</code> class (see the docs). Bypassing the shock interface may lead to unexpected or unstable behavior.</p> <p>Inputs:</p> Name Description T Amount of steps to simulate the paths excluding <code>x0</code>. shocks Array or callable generator of shocks keyed by their corresponding variable. shock_scale Scaling factor for the shocks. x0 Initial state of model variables shaped <code>(n,)</code>. (<code>None</code> defaults to zeroes) observables Include observable paths in the output <code>dict</code> if <code>True</code>. Period Specification <p>Index 0 of the output will always be an initial state. (default or specified) The input <code>T</code> will result on <code>T+1</code> array indices from index 0 to <code>T</code>.</p> <p>Returns:</p> Type Description <code>dict[str, np.ndarray[float]]</code> Arrays of paths paired with their corresponding variables. The key <code>\"_X\"</code> contains the full state matrix. (Shape <code>(T+1, n)</code>) <p> </p> <pre><code>SolvedModel.irf(\n    shocks: list[str], \n    T: int, \n    scale: float = 1.0, \n    observables: bool = False\n    ) -&gt; dict[str, np.ndarray[float]]\n</code></pre> <p>Returns the IRF paths with shocks to specified variable(s).</p> <p>Inputs:</p> Name Description shocks List of variables to receive shocks. T Time period of the IRF. scale Shock scaling factor. observables Include observables in the output if <code>True</code>. <p>Returns:</p> Type Description <code>dict[str, np.ndarray[float]]</code> The paths simulated for the IRF. Mirrors the return of <code>SolvedModel.sim</code> with a specific shock configuration. <p> </p> <p><pre><code>SolvedModel.transition_plot(\n    T: int, \n    shocks: list[str], \n    scale: float = 1.0, \n    observables: bool = False\n    ) -&gt; None \n</code></pre> Display the plot of transition paths generated by the specified shocks.</p> <p>Inputs:</p> Name Description T Time index to simulate. shocks List of variables to shock. scale Shock scaling factor. observables Include observables in the plot if <code>True</code>. <p>Returns:</p> Type Description <code>None</code> Displays a plot of the paths created by a given config. <p> </p> <p><pre><code>SolvedModel.to_dict() -&gt; dict[str, Any] \n</code></pre> Dictionary representation of the class instance.</p> <p>Inputs:</p> <p><code>None</code></p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> Dictionary representation of the <code>SolvedModel</code> object.","tags":["doc"]},{"location":"Documentation/Utilities/FRED/","title":"FRED","text":"FRED Dependencies <p><code>FRED</code> relies on the optional dependency <code>fredapi</code>. If you did not opt-in for optional dependencies, you can run:</p> <pre><code>pip install SymbolicDSGE[fred]\n</code></pre> <p>to get the required packages.</p> API Key Required <p>An API key from the \"St. Louis FED\" is required for the <code>FRED</code> class to operate. If you don't have an API key, you can generate one for free by making an account on FRED.</p> <p>FRED</p> <pre><code>class FRED(key_name: str, key_env: str | pathlib.Path | None)\n</code></pre> <p><code>FRED</code> allows easy retrieval of time series stored in the FRED database. The class can identify the given <code>key_name</code> if placed in the <code>.env</code> file anywhere in the discoverable file tree of the project. Alternatively, you can specify an <code>env</code> file that contains <code>key_name</code> in it.</p> .env File Discovery <p><code>find_dotenv</code> is used for discovery. It will walk up the directory tree towards the project root until it encounters a file named <code>\".env\"</code>.</p> <p>Methods:</p> <p><pre><code>FRED.get_series(\n    series_id: str,\n    date_range: tuple[str, str] | pd.DatetimeIndex | Literal['max', 'ytd'] | None\n) -&gt; pd.Series\n</code></pre> Returns the requested FRED series.</p> Argument Description series_id The FRED ID of the requested series. date_range Date range in either a <code>YYYY-MM-DD</code> format string pair, a <code>DatetimeIndex</code>, or a string literal <code>'max', 'ytd'</code>. <code>None</code> defaults to <code>'max'</code>. <p>Returns:</p> Type: Description <code>pd.Series</code> The requested time series in a formatted <code>pandas</code> object. <p> </p> <pre><code>FRED.get_frame(\n    series_ids: list[str],\n    date_range: tuple[str, str] | pd.DatetimeIndex | Literal['max', 'ytd'] | None\n) -&gt; pd.DataFrame\n</code></pre> <p>Returns multiple requested series in a <code>DataFrame</code>.</p> Argument Description series_ids The FRED IDs of the requested series. date_range Date range in either a <code>YYYY-MM-DD</code> format string pair, a <code>DatetimeIndex</code>, or a string literal <code>'max', 'ytd'</code>. <code>None</code> defaults to <code>'max'</code>. <p>Returns:</p> Type: Description <code>pd.DataFrame</code> The requested time series in a formatted <code>pandas</code> object.","tags":["doc"]},{"location":"Documentation/Utilities/KalmanFilter/","title":"KalmanFilter","text":"Kalman Filter Wiki Page <p>You can refer to the Wikipedia page for derivations and the underlying process. The documentation only includes the user-facing interface.</p> <p>Kalman Filter | Wikipedia</p> <pre><code>@dataclass(frozen=True)\nclass FilterResult()\n</code></pre> <p><code>dataclass</code> storing the results of a Kalman Filter application.</p> <p>Fields:</p> Name Type Description x_pred <code>np.ndarray</code> State prediction before observing \\(y_t\\). x_filt <code>np.ndarray</code> State estimate after observing \\(y_t\\). P_pred <code>np.ndarray</code> Predicted state covariance \\(P_{t\\mid t-1}\\) P_filt <code>np.ndarray</code> Filtered state covariance \\(P_{t\\mid t}\\). y_pred <code>np.ndarray</code> Predicted observation. Shape <code>(T, m)</code> innov <code>np.ndarray</code> Innovations (measurement residuals). Shape <code>(T, m)</code>. S <code>np.ndarray</code> Innovation covariance. Shape <code>(T, m, m)</code>. eps_hat <code>np.ndarray</code>, optional Estimated shocks. loglik <code>float</code>, optional Total log-likelihood of the observed data under the filter. <p> </p> <p><pre><code>class KalmanFilter()\n</code></pre> Static class containing methods necessary for filter application.</p> <p>Methods:</p> <p><pre><code>KalmanFilter.run(\n    A: np.ndarray[float64 | complex128],\n    B: np.ndarray[float64 | complex128],\n    C: np.ndarray[float64 | complex128],\n    d: np.ndarray[float64 | complex128],\n    Q: np.ndarray[float64 | complex128],\n    R: np.ndarray[float64 | complex128],\n    y: np.ndarray[float64 | complex128],\n    x0: np.ndarray[float64] | None = None,\n    P0: np.ndarray[float64] | None = None,\n    return_shocks: bool = False,\n    symmetrize: bool = True,\n    jitter: float = 0.0,\n) -&gt; FilterResult\n</code></pre> Apply a Kalman Filter using the given inputs and return a <code>FilterResult</code> object.</p> <p>Inputs:</p> Name Description A State transition matrix. B Shock loading matrix. C Observation matrix. d Observation intercept. Q Shock covariance matrix. R Observation noise covariance matrix. y Observed data over time. x0 (optional) Initial state mean. Defaults to zero vector. P0 (optional) Initial state covariance. Defaults to large diagonal. return_shocks If <code>True</code>, compute and return estimated shocks. symmetrize Symmetrize the covariance matrices at each step if <code>True</code> jitter Jitter term added to \\(S_t\\) if Cholesky solution fails. Jitter <p>Though its default is 0.0, running the method with a small jitter is strongly recommended. Using 1e-8 (or similar) can prevent fallback to matrix inversion when Cholesky fails. (Inversion much slower in comparison)</p> <p>Returns:</p> Type Description <code>FilterResult</code> <code>dataclass</code> containing results of the Kalman Filter run.","tags":["doc"]},{"location":"Documentation/Utilities/math_utils/","title":"math_utils","text":"<p><pre><code>def HP_two_sided(\n    s: pd.Series | np.ndarray,\n    lamb: float = 1600,\n) -&gt; tuple[pd.Series | np.ndarray, pd.Series | np.ndarray]\n</code></pre> Apply the Two-Sided Hodrick-Prescott filter to a time series to separate the trend and cyclical components.</p> <p>Parameters:</p> Name Type Description s <code>pd.Series | np.ndarray</code> The input time series data. lamb <code>float</code> The smoothing parameter. Default is 1600, commonly used for quarterly data. <p>Returns:</p> Type Description <code>pd.Series | np.ndarray</code> Tuple index 0. The trend component of the series. <code>pd.Series | np.ndarray</code> Tuple index 1. The cyclical component of the series. <p> </p> <p><pre><code>def HP_one_sided(\n    s: pd.Series | np.ndarray,\n    lamb: float = 1600,\n) -&gt; tuple[pd.Series | np.ndarray, pd.Series | np.ndarray]\n</code></pre> Apply the One-Sided Hodrick-Prescott filter to a time series to separate the trend and cyclical components.</p> <p>Parameters:</p> Name Type Description s <code>pd.Series | np.ndarray</code> The input time series data. lamb <code>float</code> The smoothing parameter. Default is 1600, commonly used for quarterly data. <p>Returns:</p> Type Description <code>pd.Series | np.ndarray</code> Tuple index 0. The trend component of the series. <code>pd.Series | np.ndarray</code> Tuple index 1. The cyclical component of the series. <p> </p> <p><pre><code>def annualized_log_percent(\n    s: pd.Series | np.ndarray, periods_per_year: int = 4\n) -&gt; pd.Series | np.ndarray\n</code></pre> Calculate the annualized log percent change of a time series.</p> <p>Parameters:</p> Name Type Description s <code>pd.Series | np.ndarray</code> The input time series data. periods_per_year <code>int</code> Number of periods in a year. Default is 4 for quarterly data. <p>Returns:</p> Type Description <code>pd.Series | np.ndarray</code> The annualized log percent change of the series. <p> </p> <p><pre><code>def demean(\n    s: pd.Series | np.ndarray\n) -&gt; pd.Series | np.ndarray\n</code></pre> Parameters:</p> Name Type Description s <code>pd.Series | np.ndarray</code> The input series. <p>Returns:</p> Type Description <code>pd.Series | np.ndarray</code> The demeaned series. <p> </p> <p><pre><code>def detrend(\n    s: pd.Series | np.ndarray\n) -&gt; pd.Series | np.ndarray\n</code></pre> Detrend a time series by removing its linear trend.</p> Detrending <p>This process subtracts the \"Line of Best Fit\" (LoBF) from the data. LoBF is computed as the slope and intercept that satisfy: $$ \\underset{m,b}{\\operatorname{argmin}}\\,\\ \\sum_{i=0}^n  (y_i - (mx_i+b))^2 $$</p> <p>Parameters:</p> Name Type Description s <code>pd.Series | np.ndarray</code> The input series. <p>Returns:</p> Type Description <code>pd.Series | np.ndarray</code> The detrended series.","tags":["doc"]},{"location":"Guides/config_guide/","title":"Configuration Guide","text":"TL;DR <p>You can see an example config here.</p> <p><code>SymbolicDSGE</code> models are configured through a YAML file. Similar to many familiar DSGE engines, the configuration contains:</p> <ul> <li>Parameter declarations</li> <li>Constraint definitions</li> <li>Model equations</li> <li>Measurement equations (For post-solution observables)</li> <li>Parameter calibration</li> <li>Shock symbol declarations</li> </ul> <p>This guide contains detailed information about config sections, how they are parsed, and the conventions users are expected to follow for correct parsing. The ordering of fields does not matter for the parser, however ordering of the components can change the model behavior. We will start with an empty config and build components to create a valid model in this guide.</p> <p>To start with, the configuration accepts a <code>name</code> field to specify the model's alias. This name is accessible in the parsed model but never used; it remains in the model object as a reference for users.</p> <pre><code>name: \"Test Model\"\n</code></pre>","tags":["guide"]},{"location":"Guides/config_guide/#variables","title":"Variables","text":"<p>The <code>variables</code> field contains the names for all primary model variables. (no time indices or parameters) It is declared as a list and the ordering of variables will be respected in the solver unless explicitly given a separate ordering. In addition to variable names, each variable requires an explicit boolean entry in the <code>constrained</code> field. Having this toggle allows the constraint equations to be predefined in the config but only used when explicitly enabled.</p> <p>Variables are declared as follows: <pre><code>variables: [g, z, r, Pi, x]\nconstrained:\n    g: false\n    z: false\n    r: false\n    x: false\n    Pi: false\n</code></pre></p>","tags":["guide"]},{"location":"Guides/config_guide/#parameters","title":"Parameters","text":"<p>Parameters are \"constants\" that appear in the model equations in some capacity. Common examples of parameters are:</p> <ul> <li>Shock persistence terms</li> <li>Shock (co)variances</li> <li>Steady state values</li> <li>Model parameters such as the discount factor (often \\(\\beta\\))</li> </ul> <p>Ordering of the parameters does not matter in the configuration file. The <code>parameters</code> field is again declared as a list. <pre><code>parameters: [beta, kappa, tau_inv,\n             psi_pi, psi_x, rho_r,\n             rho_g, rho_z,\n             pi_star, r_star,\n             sig_r, sig_g, sig_z,\n             rho_gz]\n</code></pre></p> Parameter Naming <p>The current config expects all shock sigmas to be defined as <code>f\"sig_{varname}\"</code> and covariance terms as f\"rho_{var1}{var2}\", where either order is accepted (<code>rho_gz</code> or <code>rho_zg</code>). The mapping layer will be updated to accept any variable name in future iterations, but the current config falls back to defaults (<code>sig_* =&gt; 1.0</code> and <code>rho_* =&gt; 0.0</code>) if shocks terms are not accompanied by a <code>sig_</code> and/or <code>rho_</code> parameter.</p> Calibration Values <p><code>SymbolicDSGE</code> currently expects each parameter to have known values. estimation/inference will be implemented but are not accessible as of now.</p>","tags":["guide"]},{"location":"Guides/config_guide/#shocks","title":"Shocks","text":"<p>Shocks are the symbols that represent the stochastic components of the model. A shock symbol is separate from its (co)variance and is used to indicate where a respective innovation should be applied in the model equations.</p> <pre><code>shocks: [e_g, e_z, e_r]\n</code></pre> <p>Shock realizations are only injected when the user selects them at simulation time. Therefore, declaring extra variables here and including them in the model equations can be used to test multiple shock configurations from a single model config.</p>","tags":["guide"]},{"location":"Guides/config_guide/#observables","title":"Observables","text":"<p>Observables map model units to real life variables via equations. For the <code>observables</code> field we only declare the names we desire to use as observable variables. <pre><code>observables: [Infl, Rate]\n</code></pre></p>","tags":["guide"]},{"location":"Guides/config_guide/#equations","title":"Equations","text":"<p>Equations contain the bulk of model dynamics. In <code>SymbolicDSGE</code> the field is used as a parent to model equations, constraints, and observable equations. We declare the necessary fields: <pre><code>equations:\n    model: ...\n    constraint: ...\n    observables: ...\n</code></pre> The equations field treats all variables as a function of time; to refer to past, current, and future observations we use <code>x(t-1)</code>, <code>x(t)</code>, and <code>x(t+1)</code> respectively.</p>","tags":["guide"]},{"location":"Guides/config_guide/#model-equations","title":"Model Equations","text":"<p>This field contains the state-space definition. Multiple equations are supplied to form all necessary interactions. <pre><code>equations:\n    model:\n        - Pi(t) = beta*Pi(t+1) + kappa*x(t) + z(t) # (1)!\n\n        - x(t) = x(t+1) - tau_inv*(r(t) - Pi(t+1)) + g(t) # (2)!\n\n        - r(t) = rho_r*r(t-1) + (1 - rho_r)*(psi_pi*Pi(t) + psi_x*x(t)) + e_r # (3)!\n\n        - g(t) = rho_g*g(t-1) + e_g # (4)!\n\n        - z(t) = rho_z*z(t-1) + e_z # (5)!\n    constraint: ...\n    observables: ...\n</code></pre></p> <ol> <li>New Keynesian Phillips Curve (NKPC)</li> <li>IS/Euler Equation</li> <li>Taylor Rule</li> <li>Demand Shock</li> <li>Cost-Push Shock</li> </ol> <p>Here, we use these variables and parameters that we defined to create the namespace.</p>","tags":["guide"]},{"location":"Guides/config_guide/#constraints","title":"Constraints","text":"<p>The constraints field is available and parsed in <code>SymbolicDSGE</code>. However, the constraints are currently not supported in the solver and therefore are not enforced. The <code>constraint</code> field takes a <code>{variable: equation, ...}</code> style dictionary. The behavior is similar for the <code>constrained</code> toggle; it will be parsed and cross-checked with the given equations. However, the solver will not act on the given equations. For correctness, we will leave the field empty in the example config.</p> <pre><code>equations:\n    model:\n        - Pi(t) = beta*Pi(t+1) + kappa*x(t) + z(t)\n\n        - x(t) = x(t+1) - tau_inv*(r(t) - Pi(t+1)) + g(t)\n\n        - r(t) = rho_r*r(t-1) + (1 - rho_r)*(psi_pi*Pi(t) + psi_x*x(t)) + e_r\n\n        - g(t) = rho_g*g(t-1) + e_g\n\n        - z(t) = rho_z*z(t-1) + e_z\n    constraint: {...}\n    observables: ...\n</code></pre>","tags":["guide"]},{"location":"Guides/config_guide/#observables_1","title":"Observables","text":"<p>This field contains the mappings of model variables to real-life observed variables. In our example, we defined two observables in the namespace; and we will define the equations to construct them here. Observable equations can be constructed from any parameter/variable combinations. If a constant is required as a scaling factor or an offset, it should be declared as a parameter (to ensure <code>SymPy</code> parses correctly). As a note, observable equations are expected to correspond to current time. Observable equations must be functions of current state variables. (no <code>t+1</code> terms)</p> <pre><code>equations:\n    model:\n        - Pi(t) = beta*Pi(t+1) + kappa*x(t) + z(t)\n\n        - x(t) = x(t+1) - tau_inv*(r(t) - Pi(t+1)) + g(t)\n\n        - r(t) = rho_r*r(t-1) + (1 - rho_r)*(psi_pi*Pi(t) + psi_x*x(t)) + e_r\n\n        - g(t) = rho_g*g(t-1) + e_g\n\n        - z(t) = rho_z*z(t-1) + e_z\n    constraint: {...}\n    observables:\n        Infl: 4*Pi(t) + pi_star # (1)!\n\n        Rate: 4*r(t) + (r_star + pi_star) # (2)!\n</code></pre> <ol> <li>Annualized inflation from quarterly gap</li> <li>Annualized nominal rate from quarterly gap. </li> </ol>","tags":["guide"]},{"location":"Guides/config_guide/#calibration","title":"Calibration","text":"<p>The <code>calibration</code> field stores values and shock variance specifications to annotate the corresponding values of all model components except the variables. The field is a parent containing two sub-fields: <pre><code>calibration:\n    parameters: ...\n    shocks: ...\n</code></pre></p>","tags":["guide"]},{"location":"Guides/config_guide/#parameters_1","title":"Parameters","text":"<p>This section is used to define the known values of model parameters.  All parameters defined in the namespace must (for now) have a value entry here. <pre><code>calibration:\n    parameters:\n        beta: 0.99\n\n        psi_pi: 2.19\n        psi_x: 0.30\n        rho_r: 0.84\n\n        pi_star: 3.43\n        r_star: 3.01\n\n        kappa: 0.58\n        tau_inv: 1.86\n\n        rho_g: 0.83\n        rho_z: 0.85\n        rho_gz: 0.36\n\n        sig_r: 0.18\n        sig_g: 0.18\n        sig_z: 0.64\n    shocks: ...\n</code></pre></p>","tags":["guide"]},{"location":"Guides/config_guide/#shocks_1","title":"Shocks","text":"<p>The shocks section maps shock variances to the corresponding terms in model equations. All terms defined in the shock namespace must have a value here.</p> Shock Selection at Simulations <p>At simulation time, shocks are specified by the exogenous state variable names (e.g., <code>g</code>, <code>z</code>) or by grouped keys (<code>\"g,z\"</code>), not by the innovation symbols (<code>e_g</code>)</p> <pre><code>calibration:\n    parameters:\n        beta: 0.99\n\n        psi_pi: 2.19\n        psi_x: 0.30\n        rho_r: 0.84\n\n        pi_star: 3.43\n        r_star: 3.01\n\n        kappa: 0.58\n        tau_inv: 1.86\n\n        rho_g: 0.83\n        rho_z: 0.85\n        rho_gz: 0.36\n\n        sig_r: 0.18\n        sig_g: 0.18\n        sig_z: 0.64\n    shocks:\n        e_g: sig_g\n        e_z: sig_z\n        e_r: sig_r\n</code></pre>","tags":["guide"]},{"location":"Guides/config_guide/#conclusion","title":"Conclusion","text":"<p>With all components defined, the configuration file now fully specifies a solvable symbolic DSGE model. The parser will construct the symbolic state-space representation, apply calibration, and prepare the model for solution and simulation. For future reference or a ready-made boilerplate, you can visit this link to see a test configuration in the <code>SymbolicDSGE</code> repository.</p>","tags":["guide"]},{"location":"Guides/quickstart/","title":"Quick Start Guide","text":"TL;DR <p>You can find a demonstration notebook here.</p> <p>This guide will follow the steps necessary to get from model parsing to simulation. We will use a pre-defined config file (accessible in the repository) <code>\"MODELS/POST82.yaml\"</code>.</p>","tags":["guide"]},{"location":"Guides/quickstart/#reading-model-configuration","title":"Reading Model Configuration","text":"<p>The configuration files are parsed by the <code>SymbolicDSGE.ModelParser</code> class. The class provides a <code>.get()</code> method to return a <code>ModelConfig</code> object.</p> <pre><code>from SymbolicDSGE import ModelParser\nfrom sympy import Matrix\nfrom warnings import simplefilter, catch_warnings\n\nmodel = ModelParser(\"MODELS/POST82.yaml\").get()\n\nwith catch_warnings(): # (1)!\n    simplefilter(action=\"ignore\")\n    mat = Matrix(model.equations.model)\nmat\n</code></pre> <ol> <li>Wrapping equations in a <code>sp.Matrix</code> is deprecated and used here solely for pretty-printing.</li> </ol> <p>We've read the config and displayed the equations in a matrix:</p> \\[     \\left[\\begin{matrix}\\Pi{\\left(t \\right)} = \\beta \\Pi{\\left(t + 1 \\right)} + \\kappa x{\\left(t \\right)} + z{\\left(t \\right)}\\\\x{\\left(t \\right)} = - \\tau_{inv} \\left(- \\Pi{\\left(t + 1 \\right)} + r{\\left(t \\right)}\\right) + g{\\left(t \\right)} + x{\\left(t + 1 \\right)}\\\\r{\\left(t \\right)} = e_{R} + \\rho_{r} r{\\left(t - 1 \\right)} + \\left(1 - \\rho_{r}\\right) \\left(\\psi_{\\pi} \\Pi{\\left(t \\right)} + \\psi_{x} x{\\left(t \\right)}\\right)\\\\g{\\left(t \\right)} = e_{g} + \\rho_{g} g{\\left(t - 1 \\right)}\\\\z{\\left(t \\right)} = e_{z} + \\rho_{z} z{\\left(t - 1 \\right)}\\end{matrix}\\right] \\] <p>We can see that all variables are converted to <code>SymPy</code> objects (symbols/functions) and are accessible through the <code>ModelConfig</code> interface.</p>","tags":["guide"]},{"location":"Guides/quickstart/#compilation","title":"Compilation","text":"<p>In compilation, the symbolic model is projected into a functionalized and completely numeric form. Time-dependent variables are separated and equations are written as lambda objectives. Finally, the solver backend <code>linearsolver</code> is exposed to a single function representing all model equations.</p> <pre><code>from SymbolicDSGE import DSGESolver\n\nsolver = DSGESolver(model)\ncompiled = solver.compile(\n    variable_order=None, # (1)!\n    params_order=None, # (2)!\n    n_state=3, # (3)!\n    n_exog=2, # (4)!\n)\n\nprint(\"Equations with symbols removed: \\n\", \"\\n\".join(map(str, compiled.objective_eqs)))\nprint(\"\\n\")\nprint(\"Equations as passed to the solver: \\n\", compiled.equations)\n</code></pre> <ol> <li><code>None | list[Function]</code>. <code>None</code> uses the order in the config file.</li> <li><code>None | list[str]</code>. <code>None</code> uses the order in the config file.</li> <li>Number of state variables (must be supplied)</li> <li>Number of exogenous variables (must be supplied)</li> </ol> <p>At compilation, the equations are transformed as shown in the code output: <pre><code>Equations with symbols removed: \n -beta*fwd_Pi + cur_Pi - cur_x*kappa - cur_z\n-cur_g + cur_x - fwd_x + tau_inv*(cur_r - fwd_Pi)\n-cur_r*rho_r - e_R + fwd_r + (rho_r - 1)*(fwd_Pi*psi_pi + fwd_x*psi_x)\n-cur_g*rho_g - e_g + fwd_g\n-cur_z*rho_z - e_z + fwd_z\n\n\nEquations as passed to the solver: \n &lt;function DSGESolver.compile.&lt;locals&gt;.equations at 0x0000012D16AB5B20&gt;\n</code></pre></p> Variable Placement <p>The solver relies on the exogenous variables being placed in the first indices. You should ensure the first <code>n_exog</code> entries of the order correctly map to the exogenous variables. (either through the config or via the ordering) </p>","tags":["guide"]},{"location":"Guides/quickstart/#solution","title":"Solution","text":"<p>The solution step takes steady-state values and optionally parameter calibrations to provide a <code>SolvedModel</code>.</p> <pre><code>from numpy import float64, array\n\nsol = solver.solve(\n    compiled,\n    parameters=None, # (1)!\n    steady_state=array([0.0, 0.0, 0.0, 0.0, 0.0], dtype=float64),\n    log_linear=False,\n)\nprint(\"Is stable: \", sol.policy.stab == 0)  # (2)! \nprint(\"Eigenvalues: \", sol.policy.eig)\n</code></pre> <ol> <li><code>None | dict[str, float]</code>. <code>None</code> uses the values in <code>ModelConfig.calibration</code></li> <li>stable if <code>sol.policy.stab == 0</code></li> </ol> <pre><code>Is stable:  True\nEigenvalues:  [0.27920118+0.j 0.83000003+0.j 0.84999992+0.j 2.56517116+0.j\n 1.18470582+0.j] (1)\n</code></pre> <ol> <li>Complex numbers are an artifact of <code>linearsolve</code>. All relevant matrices are cast to reals with <code>np.real_if_close</code></li> </ol>","tags":["guide"]},{"location":"Guides/quickstart/#inspecting-model-dynamics","title":"Inspecting Model Dynamics","text":"<p>While we can check the matrices directly, we can also use the built-in methods <code>SolvedModel.irf</code> and <code>SolvedModel.transition_plot</code> to display the dynamics.</p> <pre><code>irf_dict = sol.irf(\n    T=25,\n    shocks=[\"g\", \"z\"],\n    scale=1.0,  # (1)!\n    observables=True,  # (2)!\n)\nsol.transition_plot(\n    T=25,\n    shocks=[\"g\", \"z\"],\n    scale=1.0,\n    observables=True,\n)\nirf_dict[\"z\"] # (3)!\n</code></pre> <ol> <li><code>shock = sig_var * scale</code></li> <li>Include observables in output.</li> <li>Path of the variable <code>z</code>.</li> </ol> <p>This produces the outputs: </p> <pre><code>array([0.        , 0.64      , 0.54399995, 0.46239991, 0.39303989,\n       0.33408388, 0.28397127, 0.24137556, 0.2051692 , 0.17439381,\n       0.14823472, 0.1259995 , 0.10709957, 0.09103462, 0.07737942,\n       0.0657725 , 0.05590662, 0.04752063, 0.04039253, 0.03433365,\n       0.0291836 , 0.02480605, 0.02108514, 0.01792237, 0.01523401,\n       0.01294891])\n</code></pre>","tags":["guide"]},{"location":"Guides/quickstart/#simulation","title":"Simulation","text":"<p><code>SolvedModel</code> also supplies a <code>.sim()</code> method for simulations. The method simulates <code>T</code> steps given an initial state array and a shock specification.</p> <p>Shock specifications can take two basic forms.</p> <ul> <li>A callable returning the complete shock array: <code>Callable[[float | ndarray], ndarray]</code></li> <li>A <code>np.ndarray</code> of innovations</li> </ul> <p>Either specification is delivered to <code>.sim</code> in a dictionary corresponding to the variable the innovations are meant to effect. In case of multiple shocks with correlation the key for the dictionary uses <code>\"g,z\"</code> syntax. In correlated cases, the <code>Callable</code> option input should take a covariance matrix while the array option must be of shape <code>(T, n_correlated_shocks)</code>. (order should match the dictionary key)</p> <p><code>SymbolicDSGE.Shock</code> is an interface simplifying the shock generation process. It can produce <code>Callable</code> generators for both univariate and multivariate shocks. The class has support for all <code>SciPy</code> distributions from the <code>rv_generic</code> and <code>multi_rv_generic</code> hierarchies. Alongside <code>SciPy</code> support, custom distributions implementing the <code>.rvs</code> method are supported through the pass-through of distribution <code>args</code>/<code>kwargs</code>.</p> <pre><code>from SymbolicDSGE import Shock\n\nT = 200\nshock_gen = lambda seed: Shock( # (1)!\n    T=T,\n    dist=\"norm\",\n    multivar=True,\n    seed=seed, # (2)!\n    dist_kwargs={ # (3)!\n        \"mean\": [0.0, 0.0],\n    },\n).shock_generator() # (4)!\n\nsim_shocks = {\n    \"g,z\": shock_gen(seed=1) # (5)!\n}\n</code></pre> <ol> <li>Notice the seed argument to the class being parametrized through a lambda. This step is not necessary for functionality. It saves the code of declaring two instances with different seeds if two shocks share distributions.</li> <li>Seed is passed through here, the code below would operate the same if we used <code>seed=1</code> instead of using a lambda.</li> <li>The <code>kwargs</code> specified here are passed to the distribution object in the backend (to <code>SciPy</code>'s rvs methods in this case)</li> <li><code>shock_generator</code> produces the <code>Callable</code> object from the parameters given at class initialization. The methods either accept a float <code>sig_</code> or a covariance matrix <code>cov</code> created inside the <code>.sim</code> method.</li> <li>The value in this pair is a standalone function that does not depend on model parameters. Once created it can be reused across simulations; the appropriate sig_ or cov is constructed internally from model parameters at simulation time.</li> </ol> <p><code>shock_gen()</code> returns a callable that <code>.sim</code> uses in the simulation loop to produce shocks. With the shocks produced, we can simulate stochastic paths as follows:</p> <pre><code>import pandas as pd\n\nsim_data = sol.sim(\n    T=T,\n    x0=array([0.0, 0.0, 0.0, 0.0, 0.0], dtype=float64),  # (1)!\n    shocks=sim_shocks,\n    shock_scale=1.0,\n    observables=True,\n)\ndel sim_data[\"_X\"]  # (2)!\npd.DataFrame(sim_data).head(10)\n</code></pre> <ol> <li>Simulation starts at steady state</li> <li><code>\"_X\"</code> is a <code>ndarray</code> of all non-observable states for each time t. It is deleted here for code brevity in producing a <code>DataFrame</code>.</li> </ol> g z r Pi x Infl Rate 0 0 0 0 0 0 3.43 6.44 1 0.0113 1.0502 0 2.0097 0.4527 11.469 6.44 2 -0.2055 0.5741 0.205 -0.4441 -1.6807 1.6538 7.2601 3 -0.4925 1.0832 0.1083 0.2587 -1.8046 4.4646 6.873 4 -0.4139 2.0507 0.0962 2.3427 -1.0963 12.8009 6.8249 5 -0.3628 1.9517 0.3014 1.2818 -2.2254 8.557 7.6456 6 -0.5415 2.6315 0.3544 1.8491 -2.8505 10.8264 7.8577 7 -0.5357 2.0374 0.4482 0.2843 -3.6404 4.5671 8.233 8 -0.5484 2.477 0.362 1.503 -2.9801 9.442 7.8881 9 -0.6129 2.0109 0.4187 0.1822 -3.7172 4.1587 8.1148 <p>Alternative to a DataFrame, we can also plot the simulated paths:</p> <p><pre><code>from numpy import ceil, sqrt\nimport matplotlib.pyplot as plt\n\nfig_square = ceil(sqrt(len(sim_data))).astype(int)\nsize = (4 * fig_square, 3 * fig_square)\nfig, ax = plt.subplots(fig_square, fig_square, figsize=size)\nax = ax.flatten()\n\nwhile len(ax) &gt; len(sim_data):\n    fig.delaxes(ax[-1])\n    ax = ax[:-1]\n\nfor i, (var, path) in enumerate(sim_data.items()):\n    ax[i].plot(path)\n    ax[i].set_title(var)\n    ax[i].grid(linestyle=\":\")\nplt.suptitle(f\"Simulation over {T} periods with stochastic shocks\", fontsize=16)\nplt.tight_layout()\n</code></pre> </p>","tags":["guide"]},{"location":"Guides/quickstart/#further-steps","title":"Further Steps","text":"<p>This guide covers the basic capabilities and usage of <code>SymbolicDSGE</code>. Further tools include:</p> <ul> <li><code>SymbolicDSGE.FRED</code> for easy U.S. macro data retrieval </li> <li><code>SymbolicDSGE.math_utils</code> for basic detrending, HP filters, etc. </li> <li><code>SymbolicDSGE.KalmanFilter</code> for a one-sided Kalman Filter implementation. (standalone as of now but easy model integration interface will be developed) </li> </ul> <p>If you've read to this point and would like to inspect/interact with the code this guide refers to, you can visit this link to the file.</p> <p>Download Guide Notebook</p>","tags":["guide"]}]}